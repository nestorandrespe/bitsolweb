# The Digital Archive of the XXI century

#### Néstor Andrés Peña

In this new era, digital archives will become increasingly crucial as a means of preserving and accessing our cultural and historical information. However, the traditional approach to constructing and cataloging these archives may no longer be sufficient to keep pace with the rapidly evolving technological landscape. To fully leverage the potential of digital archives, it is essential to take advantage of recent technological developments and to adopt new strategies for building and organizing these repositories of memories. In this text, we will explore the need to rethink the traditional approach to digital archives and examine the potential benefits of new approaches for the preservation and accessibility of cultural and historical information in the digital era.

![eclipse](/images/archihub/age-01.gif)

## Context

Over the past decade, the world has undergone significant changes, particularly in the realm of digital technology which has direct and unavoidable impacts on our society. Those are readily apparent, with the acceleration of information consumption and production being the one we are going to talk about.

In today’s era, TikTok remixes and Twitter shares have become a means of expression that are now an essential part of our cultural landscape. Our communication patterns have also been transformed by the technological tools we employ. The smartphone, for instance, has made texting an omnipresent feature while communicating with someone and voice notes are a convenient way to share content in audio form. On top of that, with the advent of LLMs this is starting to become true for how we talk with our machines. Additionally, podcasts and video production have become more accessible to a broader audience, enabling anyone to create professional-quality content on their own. As the cycle of information consumption and production continues to expand, it becomes important to rethink our decisions on how we preserve our memories and what those memories are.

![social network](/images/archihub/age-02.gif)

## What to save

```
The answer, my friend, is blowin’ in the wind
The answer is blowin’ in the wind

Bob Dylan, Blowin’ in the wind
```

In my recent experience as a developer at the Museum of Memory and the Truth Commission in Colombia, I noticed something while working with digital archivists. Although there was an emphasis on preserving files created by various institutions, there was little attention given to preserving what I consider a crucial element of contemporary culture: the bits and pieces that circulate on social media.

One reason why this content is often overlooked is that the source file is usually heavily compressed, which goes against the preservation rules and steps defined for digital archives. This brings me to my initial argument: we should explore the option of preserving these files even if they differ significantly from the original. Our ways of communication are constantly evolving. We no longer document our stories solely in books; now, we do so through tweets and blogs articles. Rather than painstakingly creating physical albums of our photos, we post them on Instagram. We no longer solely take to the streets to voice our opinions; now, we use trending topics on social media.

We need to view this as a new type of document — the meme as a resource in the digital archive.

```
The answer, my friend, is blowin’ in the memes
The answer is blowin’ in the memes
```

Firstly, we need to establish a primary topic to document, such as the political landscape of a country or the focus on environmental justice. Next, we determine the significant players whose social media interactions we will record, the content that is most relevant for trending topics, the key news portals, and the interactions for a specific set of Wikipedia articles. All this content is what we will call the “discovered content”.

There are various approaches that we can use to obtain and arrange discovered content. Drawing from my own experience, I will attempt to explain each of them.

To begin, we should identify a list of key public figures, organizations, and companies that are significant for the topic of interest. Once identified, we can set up an automated system to retrieve their public posts and interactions, as well as the user interactions generated by those publications, including comments and metrics such as likes, retweets, and shares. An evaluation of the social networks we have interest in must be carried on. For example, for some topics websites such as Reddit or HackerNews might be relevant. Another necessary approach is what I like to call “trending snapshots”. Given a fixed interval of time (15m for example) the objective is to record the order of the current trending topics with a sample of posts for that topic. Nonetheless the retrieval of such information is only the first step, as we will see further in this text, we can leverage new possibilities for automated classification of that content using LLMs and an accessible UI for the researchers to tinker with new ways to classify and get insights from that data.

We’re creating a new type of digital archive that I like to call the archive of the 21st century. This doesn’t mean we’re discarding the traditional way of selecting and organizing content. Rather, we’re expanding our view of what can be included in the archive, giving us more content to work with alongside our traditional documents. For example, when we add resources to the archive, we can also keep track of their interactions, shares, and comments on social media. Instead of isolating these interactions from our content, we can incorporate them into it and make them part of that memory once we recognize their value. Alongside our documents we can have an overview of their interactions on social media and news.

In order to build a comprehensive archive, it’s important to include resources such as news articles and blogs. Just like with social media, it’s essential to carefully select relevant news portals that reflect different viewpoints and opinions on the topic of interest. But even from the same media we can have articles that have a deceiving purpose and an informative one. This distinction is important and will be addressed when we talk about the automation process. It’s also important to distinguish between the different types of publications, including editorials and opinions from collaborators if we are going to keep track of them.

This list of different origins can help us track news on a timeline related to our main research interest, and it can also be useful for identifying fake news with the help of AI agents as I will talk about later on this text. We can gather data by monitoring social media pages to see the latest posts and user interactions, as well as tracking the position of articles on the main home page, which can be useful for data visualization as the position from the top reveals the importance of the given topic for that particular article.

Wikipedia is a useful resource not just for the information in its articles, but also for the way those articles change over time. By working with the Wikimedia Foundation, we can keep track of the different versions of specific articles that are relevant to our research interests. The premise is simple: if we can visualize the editions of an article chronologically, what can that tell us about the topic addressed in that article? If we trace a timeline with the editions, will it be possible to find patterns that reveal other things that the article itself does not? [You can dig a little deeper on an experiment for the article about armed conflict in Colombia](https://medium.com/@nstorandrspea/visualizando-las-revisiones-de-los-art%C3%ADculos-en-wikipedia-d8e2586c34fa)

The other subset of our meme category is what we refer to as “given content”. To capture this type of content, we need to first understand the tools that are commonly used by communities on site and leverage them effectively.

I have three experiences in Colombia that I would like to share. The first is related to the Museum of Memory. While working in the museum’s digital lab, we were attempting to gather visitors’ opinions on various topics related to truth, forgiveness and memory. The objective was to have visitors read opinions from different individuals on the same subject, thereby facilitating connections between people with differing viewpoints. We developed what we very originally called, “the bot”. We used WhatsApp as the platform for this interaction, as it is the primary messaging app used in Colombia and it’s familiar to most people. The visitor was allowed to choose a concept, gave his opinion of it and in return got another opinion on the same subject from somebody else. At first, I was unaware of the additional benefit of using a smartphone app: the storytelling experience was more personal and intimate because visitors were in their own personal space with their devices. You can see the full extent of the work done in the museum here.

The second one is very similar and was made with the team at IDARTES (District Institute of the Arts). Using a Telegram bot made in house, we launched an online radio that played the voice messages anyone sended on the chat. In 2022, while there were protests against the government in the streets of Colombia during the pandemic, an instance of the bot called “Radio Cacerola” was initiated, through which people were asked to send their audio reports, which were then played online. This implementation of the “bot concept” allowed for an amplification of those stories rather than a conversation, as it was the case previously.

The final and more recent example I've participated in was again in a project with IDARTES. When I joined an ongoing project that aims to establish a network of vegetable gardens in the city, I proposed a system to collect and display various data about each garden, such as humidity, temperature, and amount of light. However, during our discussions, I realized that the project’s participants were not interested in recording these technical details. Instead, they wanted to document the stories, activities, and communities associated with each garden. I realized that it would be more effective to redesign the “bot concept” by integrating it into an archival tool. This required me to first automatically transcribe the audio and develop a system for categorizing these memories. To accomplish this, I used AI models and a new node-based programming interface for large language models (LLMs) that I created for this and other text-processing projects.

![social network](/images/archihub/age-03.webp)


![social network](/images/archihub/age-04.webp)

In traditional archives, certain practices have always been followed. However, by using new tools and interfaces, we can expand these practices and explore new possibilities. The main goal is to generate insights that will enhance research and provide useful content for remixing and publishing.

We’ve discussed the new types of content that could be included in the meme category. Now we need to figure out how to save these new resources. What tools should we use, which fields should we focus on, and how can we store everything so that it can be easily accessed using vector databases and semantic search.